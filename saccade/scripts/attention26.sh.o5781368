------------------------------
i am running on node09.cluster
started at Fri Mar 4 06:27:53 EST 2016
in /jukebox/buschman/Users/cjw5/Thesis/saccade/scripts
by cjw5
via the command:
pni_submit attention26.sh
------------------------------
PyCuda not installed, or no compatible device detected
Reading in experiment

{u'delay': False, u'locs': False, u'cue': False}

2444.0
8114.0


Experiment Data: 
{'input_side': 11, 'description': 'attention experiment', 'train_file': 'attention26.train', 'phase_times': {u'delay': 5, u'output': 5, u'cue': 3, u'locs': 5}, 'init_weights': 'init_weights', 'num_locs': 8, 'name': 'attention26', 'input_layer': 125, 'hidden_layer': 25, 'train_pct': 90, 'loc_connect': 'false', 'out_layer': 4, 'directory': 'experiments/attention26/', 'total_length': 18, 'phase_var': {u'delay': False, u'locs': False, u'cue': False}, 'variance': 2, 'type': 'attention', 'train_shuffle': 'true'}

experiments/attention26/attention26.train
attention26
Total number of inputSpaces is: 1
Deleting Space Default Space.
No more inputSpaces
Beginning Training
Epoch Number: 0
========================================
batch 0
grad norm 18.3053
CG steps 23
using iteration 14
err 16.1758804321
new_err 2.98530515035
improvement_ratio 1.00225726688
damping 0.66
min_improv -0.238893127441
l_rate 1.0
l_rate_err 2.98530515035
improvement -13.1905752818
test error 2.98530515035
Epoch Number: 1
Epoch Number: 2
Epoch Number: 3
Epoch Number: 4
Epoch Number: 5
Epoch Number: 6
Epoch Number: 7
Epoch Number: 8
Epoch Number: 9
Epoch Number: 10
========================================
batch 10
grad norm 0.0249181
CG steps 31
using iteration 29
err 1.80220778783
new_err 1.7978181839
improvement_ratio 0.91726114504
damping 0.010351023414
min_improv -5.86007954553e-05
l_rate 1.0
l_rate_err 1.7978181839
improvement -0.0043896039327
test error 1.7978181839
Epoch Number: 11
Epoch Number: 12
Epoch Number: 13
Epoch Number: 14
Epoch Number: 15
Epoch Number: 16
Epoch Number: 17
Epoch Number: 18
Epoch Number: 19
Epoch Number: 20
========================================
batch 20
grad norm 3.49017
CG steps 99
using iteration 62
err 1.59815502167
new_err 2.13721895218
improvement_ratio -2.59268134488
damping 0.00190574424485
min_improv -0.00365672498941
l_rate 0.512
l_rate_err 1.58996311824
improvement -0.00819190343221
test error 1.58996311824
Epoch Number: 21
Epoch Number: 22
Epoch Number: 23
Epoch Number: 24
Epoch Number: 25
Epoch Number: 26
Epoch Number: 27
Epoch Number: 28
Epoch Number: 29
Epoch Number: 30
========================================
batch 30
grad norm 12.7989
CG steps 99
using iteration 99
err 0.831778526306
new_err 0.780440251033
improvement_ratio 0.368322876993
damping 0.00420259485236
min_improv -0.00243215188384
l_rate 1.0
l_rate_err 0.780440251033
improvement -0.0513382752736
test error 0.780440251033
Epoch Number: 31
Epoch Number: 32
Epoch Number: 33
Epoch Number: 34
Epoch Number: 35
Epoch Number: 36
Epoch Number: 37
Epoch Number: 38
Epoch Number: 39
Epoch Number: 40
========================================
batch 40
grad norm 4.23042
CG steps 99
using iteration 37
err 0.0693335682154
new_err 0.0662560214599
improvement_ratio 0.394182175146
damping 0.00274597547653
min_improv -0.000128077939153
l_rate 1.0
l_rate_err 0.0662560214599
improvement -0.00307754675547
test error 0.0662560214599
Epoch Number: 41
Epoch Number: 42
Epoch Number: 43
Epoch Number: 44
Epoch Number: 45
Epoch Number: 46
Epoch Number: 47
Epoch Number: 48
Epoch Number: 49
Epoch Number: 50
========================================
batch 50
grad norm 38.5945
CG steps 99
using iteration 99
err 0.0257741312186
new_err 0.0239912122488
improvement_ratio 0.68571073796
damping 0.00908324065535
min_improv -4.39241528511e-05
l_rate 1.0
l_rate_err 0.0239912122488
improvement -0.00178291896979
test error 0.0239912122488
Epoch Number: 51
Epoch Number: 52
Epoch Number: 53
Epoch Number: 54
Epoch Number: 55
Epoch Number: 56
Epoch Number: 57
Epoch Number: 58
Epoch Number: 59
Epoch Number: 60
========================================
batch 60
grad norm 5.56636
CG steps 99
using iteration 48
err 0.0190706700087
new_err 0.0190221841137
improvement_ratio 0.554010469458
damping 0.000750765719111
min_improv -1.74161978066e-06
l_rate 1.0
l_rate_err 0.0190221841137
improvement -4.84858949979e-05
test error 0.0190221841137
Epoch Number: 61
Epoch Number: 62
Epoch Number: 63
Epoch Number: 64
Epoch Number: 65
Epoch Number: 66
Epoch Number: 67
Epoch Number: 68
Epoch Number: 69
Epoch Number: 70
========================================
batch 70
grad norm 16.6314
CG steps 99
using iteration 99
err 0.0183350568016
new_err 0.0183167035381
improvement_ratio 0.150664892939
damping 0.0016390512596
min_improv -2.17970460653e-06
l_rate 1.0
l_rate_err 0.0183167035381
improvement -1.83532635371e-05
test error 0.0183167035381
Epoch Number: 71
Epoch Number: 72
Epoch Number: 73
Epoch Number: 74
Epoch Number: 75
Epoch Number: 76
Epoch Number: 77
Epoch Number: 78
Epoch Number: 79
Epoch Number: 80
========================================
batch 80
grad norm 3.84952
CG steps 99
using iteration 99
err 0.0179924691717
new_err 0.0179708823562
improvement_ratio 0.754096582837
damping 0.000311005649413
min_improv -3.87529144064e-07
l_rate 1.0
l_rate_err 0.0179708823562
improvement -2.15868155162e-05
test error 0.0179708823562
Epoch Number: 81
Epoch Number: 82
Epoch Number: 83
Epoch Number: 84
Epoch Number: 85
Epoch Number: 86
Epoch Number: 87
Epoch Number: 88
Epoch Number: 89
Epoch Number: 90
========================================
batch 90
grad norm 2.24648
CG steps 99
using iteration 80
err 0.017785632362
new_err 0.0177630571028
improvement_ratio 0.855958649852
damping 4.87761630146e-06
min_improv -3.19126993418e-07
l_rate 1.0
l_rate_err 0.0177630571028
improvement -2.25752592087e-05
test error 0.0177630571028
Epoch Number: 91
Epoch Number: 92
Epoch Number: 93
Epoch Number: 94
Epoch Number: 95
Epoch Number: 96
Epoch Number: 97
Epoch Number: 98
Epoch Number: 99
Epoch Number: 100
========================================
batch 100
grad norm 3.26253
CG steps 99
using iteration 99
err 0.0175781970223
new_err 0.0175627221664
improvement_ratio 0.814292758977
damping 1.75613993033e-07
min_improv -2.50864541158e-07
l_rate 1.0
l_rate_err 0.0175627221664
improvement -1.54748558998e-05
test error 0.0175627221664
Epoch Number: 101
Epoch Number: 102
Epoch Number: 103
Epoch Number: 104
Epoch Number: 105
Epoch Number: 106
Epoch Number: 107
Epoch Number: 108
Epoch Number: 109
Epoch Number: 110
========================================
batch 110
grad norm 0.106097
CG steps 99
using iteration 99
err 0.0174675881863
new_err 0.0174585406979
improvement_ratio 0.945919631373
damping 2.75421902078e-09
min_improv -1.1009949958e-07
l_rate 1.0
l_rate_err 0.0174585406979
improvement -9.04748837153e-06
test error 0.0174585406979
Epoch Number: 111
Epoch Number: 112
Epoch Number: 113
Epoch Number: 114
Epoch Number: 115
Epoch Number: 116
Epoch Number: 117
Epoch Number: 118
Epoch Number: 119
Epoch Number: 120
========================================
batch 120
grad norm 0.296733
CG steps 99
using iteration 99
err 0.017387719204
new_err 0.0173806684713
improvement_ratio 0.981327878391
damping 4.31954326839e-11
min_improv -8.13421138446e-08
l_rate 1.0
l_rate_err 0.0173806684713
improvement -7.05073277155e-06
test error 0.0173806684713
Epoch Number: 121
Epoch Number: 122
Epoch Number: 123
Epoch Number: 124
Epoch Number: 125
Epoch Number: 126
Epoch Number: 127
Epoch Number: 128
Epoch Number: 129
Epoch Number: 130
========================================
batch 130
grad norm 0.193424
CG steps 99
using iteration 99
err 0.0173273471495
new_err 0.0173223863045
improvement_ratio 0.990920614296
damping 6.7744990165e-13
min_improv -5.32567355549e-08
l_rate 1.0
l_rate_err 0.0173223863045
improvement -4.96084491412e-06
test error 0.0173223863045
Epoch Number: 131
Epoch Number: 132
Epoch Number: 133
Epoch Number: 134
Epoch Number: 135
Epoch Number: 136
Epoch Number: 137
Epoch Number: 138
Epoch Number: 139
Epoch Number: 140
========================================
batch 140
grad norm 0.21365
CG steps 99
using iteration 99
err 0.0172790537278
new_err 0.0172743002574
improvement_ratio 0.990817701536
damping 1.06246966573e-14
min_improv -5.18514207215e-08
l_rate 1.0
l_rate_err 0.0172743002574
improvement -4.75347042084e-06
test error 0.0172743002574
Epoch Number: 141
Epoch Number: 142
Epoch Number: 143
Epoch Number: 144
Epoch Number: 145
Epoch Number: 146
Epoch Number: 147
Epoch Number: 148
Epoch Number: 149
Epoch Number: 150
========================================
batch 150
grad norm 0.00984648
CG steps 99
using iteration 80
err 0.0172376806537
new_err 0.0172338287036
improvement_ratio 0.996525437109
damping 1.66631036161e-16
min_improv -4.11041901316e-08
l_rate 1.0
l_rate_err 0.0172338287036
improvement -3.85195016861e-06
test error 0.0172338287036
[125, 25, 25, 4]
index & self.W:
3904
3904
Saving Weight Matrix W and network dimensions
Finished Training: Recording outputs

Training Successful \(0_0)/
