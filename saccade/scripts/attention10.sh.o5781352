------------------------------
i am running on node40.cluster
started at Fri Mar 4 06:27:53 EST 2016
in /jukebox/buschman/Users/cjw5/Thesis/saccade/scripts
by cjw5
via the command:
pni_submit attention10.sh
------------------------------
PyCuda not installed, or no compatible device detected
Reading in experiment

{u'delay': False, u'locs': False, u'cue': False}

2444.0
8157.0


Experiment Data: 
{'input_side': 11, 'description': 'attention experiment', 'train_file': 'attention10.train', 'phase_times': {u'delay': 5, u'output': 5, u'cue': 3, u'locs': 5}, 'init_weights': 'init_weights', 'num_locs': 4, 'name': 'attention10', 'input_layer': 125, 'hidden_layer': 25, 'train_pct': 90, 'loc_connect': 'false', 'out_layer': 4, 'directory': 'experiments/attention10/', 'total_length': 18, 'phase_var': {u'delay': False, u'locs': False, u'cue': False}, 'variance': 2, 'type': 'attention', 'train_shuffle': 'true'}

experiments/attention10/attention10.train
attention10
Total number of inputSpaces is: 1
Deleting Space Default Space.
No more inputSpaces
Beginning Training
Epoch Number: 0
========================================
batch 0
grad norm 5.08417
CG steps 27
using iteration 27
err 30.7110671997
new_err 13.0536295573
improvement_ratio 2.26690007224
damping 0.66
min_improv -0.102709989548
l_rate 1.0
l_rate_err 13.0536295573
improvement -17.6574376424
test error 13.0536295573
Epoch Number: 1
Epoch Number: 2
Epoch Number: 3
Epoch Number: 4
Epoch Number: 5
Epoch Number: 6
Epoch Number: 7
Epoch Number: 8
Epoch Number: 9
Epoch Number: 10
========================================
batch 10
grad norm 0.0308875
CG steps 29
using iteration 23
err 1.89171632131
new_err 1.88225634893
improvement_ratio 0.939996164157
damping 0.010351023414
min_improv -0.000124118421227
l_rate 1.0
l_rate_err 1.88225634893
improvement -0.00945997238159
test error 1.88225634893
Epoch Number: 11
Epoch Number: 12
Epoch Number: 13
Epoch Number: 14
Epoch Number: 15
Epoch Number: 16
Epoch Number: 17
Epoch Number: 18
Epoch Number: 19
Epoch Number: 20
========================================
batch 20
grad norm 22.2568
CG steps 80
using iteration 80
err 1.52714729309
new_err 1.46715450287
improvement_ratio 1.0032086846
damping 0.00984372027301
min_improv -0.000877116024494
l_rate 1.0
l_rate_err 1.46715450287
improvement -0.0599927902222
test error 1.46715450287
Epoch Number: 21
Epoch Number: 22
Epoch Number: 23
Epoch Number: 24
Epoch Number: 25
Epoch Number: 26
Epoch Number: 27
Epoch Number: 28
Epoch Number: 29
Epoch Number: 30
========================================
batch 30
grad norm 672.51
CG steps 69
using iteration 48
err 1.23053487142
new_err 1.31187637647
improvement_ratio -3.2941738761
damping 0.048353719182
min_improv -0.000377750396729
l_rate 0.262144
l_rate_err 1.2292936643
improvement -0.0012412071228
test error 1.2292936643
Epoch Number: 31
Epoch Number: 32
Epoch Number: 33
Epoch Number: 34
Epoch Number: 35
Epoch Number: 36
Epoch Number: 37
Epoch Number: 38
Epoch Number: 39
Epoch Number: 40
========================================
batch 40
grad norm 567.979
CG steps 37
using iteration 29
err 1.19444386164
new_err 1.19256051381
improvement_ratio 0.257112555909
damping 0.244790703359
min_improv -9.7668170929e-05
l_rate 1.0
l_rate_err 1.19256051381
improvement -0.00188334782918
test error 1.19256051381
Epoch Number: 41
Epoch Number: 42
Epoch Number: 43
Epoch Number: 44
Epoch Number: 45
Epoch Number: 46
Epoch Number: 47
Epoch Number: 48
Epoch Number: 49
Epoch Number: 50
========================================
batch 50
grad norm 212.221
CG steps 33
using iteration 29
err 1.16913493474
new_err 1.16709033648
improvement_ratio 0.674718069761
damping 0.367186055038
min_improv -3.26818227768e-05
l_rate 1.0
l_rate_err 1.16709033648
improvement -0.00204459826152
test error 1.16709033648
Epoch Number: 51
Epoch Number: 52
Epoch Number: 53
Epoch Number: 54
Epoch Number: 55
Epoch Number: 56
Epoch Number: 57
Epoch Number: 58
Epoch Number: 59
Epoch Number: 60
========================================
batch 60
grad norm 146.313
CG steps 33
using iteration 29
err 1.15003323555
new_err 1.14832814535
improvement_ratio 0.759034722666
damping 0.242342796325
min_improv -2.361536026e-05
l_rate 1.0
l_rate_err 1.14832814535
improvement -0.00170509020487
test error 1.14832814535
Epoch Number: 61
Epoch Number: 62
Epoch Number: 63
Epoch Number: 64
Epoch Number: 65
Epoch Number: 66
Epoch Number: 67
Epoch Number: 68
Epoch Number: 69
Epoch Number: 70
========================================
batch 70
grad norm 164.591
CG steps 20
using iteration 20
err 1.13109707832
new_err 1.12954775492
improvement_ratio 0.650523498107
damping 0.242342796325
min_improv -2.62269377708e-05
l_rate 1.0
l_rate_err 1.12954775492
improvement -0.00154932339986
test error 1.12954775492
Epoch Number: 71
Epoch Number: 72
Epoch Number: 73
Epoch Number: 74
Epoch Number: 75
Epoch Number: 76
Epoch Number: 77
Epoch Number: 78
Epoch Number: 79
Epoch Number: 80
========================================
batch 80
grad norm 113.189
CG steps 29
using iteration 23
err 1.11795258522
new_err 1.11676136653
improvement_ratio 0.662098972234
damping 0.159946245575
min_improv -2.01532244682e-05
l_rate 1.0
l_rate_err 1.11676136653
improvement -0.00119121869405
test error 1.11676136653
Epoch Number: 81
Epoch Number: 82
Epoch Number: 83
Epoch Number: 84
Epoch Number: 85
Epoch Number: 86
Epoch Number: 87
Epoch Number: 88
Epoch Number: 89
Epoch Number: 90
========================================
batch 90
grad norm 38.8568
CG steps 71
using iteration 71
err 1.10840551058
new_err 1.1076148351
improvement_ratio 0.624094039097
damping 0.0696725845723
min_improv -1.37036293745e-05
l_rate 1.0
l_rate_err 1.1076148351
improvement -0.000790675481161
test error 1.1076148351
Epoch Number: 91
Epoch Number: 92
Epoch Number: 93
Epoch Number: 94
Epoch Number: 95
Epoch Number: 96
Epoch Number: 97
Epoch Number: 98
Epoch Number: 99
Epoch Number: 100
========================================
batch 100
grad norm 29.6919
CG steps 69
using iteration 62
err 1.09975075722
new_err 1.09901309013
improvement_ratio 0.730894017857
damping 0.0200305893742
min_improv -1.22449547052e-05
l_rate 1.0
l_rate_err 1.09901309013
improvement -0.00073766708374
test error 1.09901309013
Epoch Number: 101
Epoch Number: 102
Epoch Number: 103
Epoch Number: 104
Epoch Number: 105
Epoch Number: 106
Epoch Number: 107
Epoch Number: 108
Epoch Number: 109
Epoch Number: 110
========================================
batch 110
grad norm 92.5307
CG steps 99
using iteration 37
err 1.01232933998
new_err 2.23227405548
improvement_ratio -6.92407069108
damping 0.00558767474862
min_improv -0.0028596496582
l_rate 0.068719476736
l_rate_err 1.01054859161
improvement -0.00178074836731
test error 1.01054859161
Epoch Number: 111
Epoch Number: 112
Epoch Number: 113
Epoch Number: 114
Epoch Number: 115
Epoch Number: 116
Epoch Number: 117
Epoch Number: 118
Epoch Number: 119
Epoch Number: 120
========================================
batch 120
grad norm 2345.13
CG steps 99
using iteration 80
err 0.142200440168
new_err 0.263957738876
improvement_ratio -1.58557123297
damping 0.0623805302406
min_improv -0.00120937347412
l_rate 0.16777216
l_rate_err 0.140170147022
improvement -0.00203029314677
test error 0.140170147022
Epoch Number: 121
Epoch Number: 122
Epoch Number: 123
Epoch Number: 124
Epoch Number: 125
Epoch Number: 126
Epoch Number: 127
Epoch Number: 128
Epoch Number: 129
Epoch Number: 130
========================================
batch 130
grad norm 10.0209
CG steps 99
using iteration 99
err 0.00982101509968
new_err 0.00691230284671
improvement_ratio 0.858448133692
damping 0.00505339288363
min_improv -3.8428902626e-05
l_rate 1.0
l_rate_err 0.00691230284671
improvement -0.00290871225297
test error 0.00691230284671
Epoch Number: 131
Epoch Number: 132
Epoch Number: 133
Epoch Number: 134
Epoch Number: 135
Epoch Number: 136
Epoch Number: 137
Epoch Number: 138
Epoch Number: 139
Epoch Number: 140
========================================
batch 140
grad norm 2.42332
CG steps 99
using iteration 99
err 0.000518585826891
new_err 0.000405249729132
improvement_ratio 0.759271188838
damping 0.000417682882815
min_improv -1.94735825062e-06
l_rate 1.0
l_rate_err 0.000405249729132
improvement -0.00011333609776
test error 0.000405249729132
Epoch Number: 141
Epoch Number: 142
Epoch Number: 143
Epoch Number: 144
Epoch Number: 145
Epoch Number: 146
Epoch Number: 147
Epoch Number: 148
Epoch Number: 149
Epoch Number: 150
========================================
batch 150
grad norm 0.019538
CG steps 99
using iteration 99
err 2.26732784843e-05
new_err 1.606431033e-05
improvement_ratio 0.725969996405
damping 1.50382798357e-05
min_improv -1.05767976493e-07
l_rate 1.0
l_rate_err 1.606431033e-05
improvement -6.60896815437e-06
test error 1.606431033e-05
[125, 25, 25, 4]
index & self.W:
3904
3904
Saving Weight Matrix W and network dimensions
Finished Training: Recording outputs

Training Successful \(0_0)/
